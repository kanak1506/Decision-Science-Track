{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12333510,"sourceType":"datasetVersion","datasetId":7774782},{"sourceId":12334315,"sourceType":"datasetVersion","datasetId":7775280},{"sourceId":12338866,"sourceType":"datasetVersion","datasetId":7775507}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# FEATURE-FACTORY v1 for AMEX Challenge\nimport pandas as pd, numpy as np, gc, time, sys\nfrom pathlib import Path\n\nRAW_DIR = Path('/kaggle/input/amexda')            # original competition data\n\n# Locate cleaned data produced in Step-3\ndef locate_clean_dir() -> Path:\n    wd = Path('/kaggle/working')\n    if (wd / 'train_clean.parquet').exists():\n        return wd\n    for ds in Path('/kaggle/input').iterdir():\n        if (ds / 'train_clean.parquet').exists():\n            return ds\n    raise FileNotFoundError('train_clean.parquet not found. Add the Data-Prep notebook output as a dataset or keep running in the same session.')\n\nCLEAN_DIR = locate_clean_dir()\nprint('âœ“ using cleaned files from â†’', CLEAN_DIR)\n\nWORK_DIR   = Path('/kaggle/working')\nWORK_DIR.mkdir(exist_ok=True, parents=True)\nOUT_TRAIN  = WORK_DIR / 'fe_v1_train.parquet'\nOUT_TEST   = WORK_DIR / 'fe_v1_test.parquet'\n\n# Fast-path: skip if features already built\nif OUT_TRAIN.exists() and OUT_TEST.exists():\n    print('âœ” fe_v1_* already exists â€“ skipping regeneration.')\n    sys.exit(0)\n\n# 1 â–¸ load cleaned data\nt0 = time.time()\ntrain = pd.read_parquet(CLEAN_DIR / 'train_clean.parquet')\ntest  = pd.read_parquet(CLEAN_DIR / 'test_clean.parquet')\nprint(f'loaded clean data  ({time.time()-t0:.1f}s)')\n\n# Force id2 and id3 to int64 in train/test\ntrain['id2'] = pd.to_numeric(train['id2'], errors='coerce').astype('int64')\ntrain['id3'] = pd.to_numeric(train['id3'], errors='coerce').astype('int64')\ntest['id2'] = pd.to_numeric(test['id2'], errors='coerce').astype('int64')\ntest['id3'] = pd.to_numeric(test['id3'], errors='coerce').astype('int64')\n\n# 2 â–¸ minimal events table (impression / click)\nevents_cols = ['id2', 'id3', 'id4', 'id7']\nevents = pd.read_parquet(RAW_DIR / 'add_event.parquet', columns=events_cols)\nevents['id2'] = pd.to_numeric(events['id2'], errors='coerce').astype('int64')\nevents['id3'] = pd.to_numeric(events['id3'], errors='coerce').astype('int64')\n\nevents['imp']   = 1\nevents['click'] = events['id7'].notna().astype('int8')\n\n# 3 â–¸ customer Ã— offer aggregates\nagg = (events\n       .groupby(['id2', 'id3'])\n       .agg(imp_cnt=('imp', 'sum'),\n            click_cnt=('click', 'sum'))\n       .reset_index())\nagg['ctr_id2_id3'] = agg['click_cnt'] / agg['imp_cnt']\n\n# 4 â–¸ global offer popularity & customer engagement\noffer_agg = (agg.groupby('id3')\n                 .agg(offer_imp_cnt=('imp_cnt', 'sum'),\n                      offer_click_cnt=('click_cnt', 'sum'))\n                 .reset_index())\noffer_agg['offer_ctr'] = offer_agg['offer_click_cnt'] / offer_agg['offer_imp_cnt']\n\ncust_agg = (agg.groupby('id2')\n                .agg(cust_imp_cnt=('imp_cnt', 'sum'),\n                     cust_click_cnt=('click_cnt', 'sum'))\n                .reset_index())\ncust_agg['cust_ctr'] = cust_agg['cust_click_cnt'] / cust_agg['cust_imp_cnt']\n\ndel events ; gc.collect()\n\n# 5 â–¸ merge all signals into train & test\ndef enrich(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()\n    df['id2'] = pd.to_numeric(df['id2'], errors='coerce').astype('int64')\n    df['id3'] = pd.to_numeric(df['id3'], errors='coerce').astype('int64')\n    df = (df.merge(agg,       on=['id2', 'id3'], how='left')\n            .merge(offer_agg, on='id3',          how='left')\n            .merge(cust_agg,  on='id2',          how='left'))\n    num_cols = df.select_dtypes(include=[np.number]).columns\n    df[num_cols] = df[num_cols].fillna(0).astype('float32')\n    return df\n\ntrain = enrich(train)\ntest  = enrich(test)\n\n# 6 â–¸ save feature matrices\ntrain.to_parquet(OUT_TRAIN, index=False)\ntest.to_parquet (OUT_TEST,  index=False)\nprint('ðŸŽ‰ fe_v1 files written â†’', OUT_TRAIN, ',', OUT_TEST)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T22:40:18.395697Z","iopub.execute_input":"2025-06-30T22:40:18.397216Z","iopub.status.idle":"2025-06-30T22:42:50.810338Z","shell.execute_reply.started":"2025-06-30T22:40:18.397167Z","shell.execute_reply":"2025-06-30T22:42:50.809324Z"}},"outputs":[{"name":"stdout","text":"âœ“ using cleaned files from â†’ /kaggle/input/jnbhjkbkbk\nloaded clean data  (19.5s)\nðŸŽ‰ fe_v1 files written â†’ /kaggle/working/fe_v1_train.parquet , /kaggle/working/fe_v1_test.parquet\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\n\n# Paths\nRAW_DIR = Path('/kaggle/input/amexda')\nFEAT_DIR = Path('/kaggle/input/wdwfdws')\nWORK_DIR = Path('/kaggle/working')\n\n# Load previous features\ntrain = pd.read_parquet(FEAT_DIR / 'fe_v1_train.parquet')\ntest = pd.read_parquet(FEAT_DIR / 'fe_v1_test.parquet')\n\n# Load transaction data\ntrans = pd.read_parquet(RAW_DIR / 'add_trans.parquet')\ntrans['id2'] = pd.to_numeric(trans['id2'], errors='coerce')\ntrans['f367'] = pd.to_numeric(trans['f367'], errors='coerce')  # transaction amount\ntrans['f370'] = pd.to_datetime(trans['f370'], errors='coerce')  # transaction date\n\n# Aggregate features per customer\ntrans_agg = trans.groupby('id2').agg(\n    trans_count=('f367', 'count'),\n    trans_total_amt=('f367', 'sum'),\n    trans_avg_amt=('f367', 'mean'),\n    last_trans_date=('f370', 'max')\n).reset_index()\n\n# For recency, need the impression date from train/test\nfor df, name in [(train, 'train'), (test, 'test')]:\n    df['id2'] = pd.to_numeric(df['id2'], errors='coerce')\n    df['id5'] = pd.to_datetime(df['id5'], errors='coerce')  # impression date\n    df = df.merge(trans_agg, on='id2', how='left')\n    df['trans_recency_days'] = (df['id5'] - df['last_trans_date']).dt.days\n    df['trans_recency_days'] = df['trans_recency_days'].fillna(df['trans_recency_days'].max())\n    df['trans_count'] = df['trans_count'].fillna(0)\n    df['trans_total_amt'] = df['trans_total_amt'].fillna(0)\n    df['trans_avg_amt'] = df['trans_avg_amt'].fillna(0)\n    df = df.drop(columns=['last_trans_date'])\n    # Save updated DataFrame\n    if name == 'train':\n        train = df\n    else:\n        test = df\n\n# Save as new feature set\ntrain.to_parquet(WORK_DIR / 'fe_v2_train.parquet', index=False)\ntest.to_parquet(WORK_DIR / 'fe_v2_test.parquet', index=False)\nprint('ðŸŽ‰ v2 features with transaction recency/frequency saved!')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T09:08:28.203209Z","iopub.execute_input":"2025-07-01T09:08:28.204037Z","iopub.status.idle":"2025-07-01T09:10:16.567386Z","shell.execute_reply.started":"2025-07-01T09:08:28.203997Z","shell.execute_reply":"2025-07-01T09:10:16.565828Z"}},"outputs":[{"name":"stdout","text":"ðŸŽ‰ v2 features with transaction recency/frequency saved!\n","output_type":"stream"}],"execution_count":2}]}